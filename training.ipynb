{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import BCELoss\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import vitmbt\n",
    "import mbt\n",
    "import ablation\n",
    "import helpers\n",
    "reload(mbt)\n",
    "reload(ablation)\n",
    "reload(helpers)\n",
    "reload(vitmbt)\n",
    "from helpers import ClassifierMetrics, display_tensor_as_rgb\n",
    "# from vitmbt import ViTMBT, train, val\n",
    "from vitmbt import ViTAudio, train_audio as train, val_audio as val\n",
    "from data import EmoDataset, new_collate_fn, load_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio layers...\n",
      "torch.Size([1, 1, 1024]) torch.Size([1, 184, 1024])\n",
      "Loaded successfully in 4.9s\n",
      "Reset trainable parameters of layer = 18.norm1\n",
      "Reset trainable parameters of layer = 18.attn.qkv\n",
      "Reset trainable parameters of layer = 18.attn.proj\n",
      "Reset trainable parameters of layer = 18.norm2\n",
      "Reset trainable parameters of layer = 18.mlp.fc1\n",
      "Reset trainable parameters of layer = 18.mlp.fc2\n",
      "Reset trainable parameters of layer = 19.norm1\n",
      "Reset trainable parameters of layer = 19.attn.qkv\n",
      "Reset trainable parameters of layer = 19.attn.proj\n",
      "Reset trainable parameters of layer = 19.norm2\n",
      "Reset trainable parameters of layer = 19.mlp.fc1\n",
      "Reset trainable parameters of layer = 19.mlp.fc2\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\"\n",
    "PRETRAINED_CHKPT = \"./pretrained_models/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz\"\n",
    "EPOCHS = 200\n",
    "lr = 0.00001\n",
    "BATCH_SZ = 2\n",
    "LABELS = 8\n",
    "SPLIT = [.9, 0.05, 0.05]\n",
    "vmbt = ViTAudio(1024, num_class=LABELS, bottle_layer=20, freeze_first=18, num_layers=24)\n",
    "vmbt = nn.DataParallel(vmbt).cuda()\n",
    "\n",
    "\n",
    "train_dl, val_dl, test_dl  = load_data(f\"{DATA_DIR}/Labels/all_pruned.csv\", \n",
    "                                       batch_sz=BATCH_SZ,\n",
    "                                       train_val_test_split=SPLIT)\n",
    "\n",
    "optimizer = torch.optim.AdamW(vmbt.parameters(), betas=(0.9, 0.999), lr=lr, weight_decay=1.0 / BATCH_SZ)\n",
    "# optimizer = torch.optim.SGD(vmbt.parameters(), lr=lr, momentum=momentum, weight_decay=1/BATCH_SZ)\n",
    "\n",
    "loss_func = BCELoss()\n",
    "train_cls = ClassifierMetrics(task='multilabel', n_labels=LABELS, device=DEVICE)\n",
    "val_cls = ClassifierMetrics(task='multilabel', n_labels=LABELS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cebcda5354a458d92bebee0d532bf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     train_metrics \u001b[39m=\u001b[39m train(vmbt, train_dl, optimizer, loss_fn\u001b[39m=\u001b[39;49mloss_func, cls_metrics\u001b[39m=\u001b[39;49mtrain_cls)\n\u001b[1;32m      3\u001b[0m     train_loss, train_f1, train_r, train_p, train_acc \u001b[39m=\u001b[39m train_metrics\n\u001b[1;32m      4\u001b[0m     val_metrics \u001b[39m=\u001b[39m val(vmbt, val_dl, loss_fn\u001b[39m=\u001b[39mloss_func, cls_metrics\u001b[39m=\u001b[39mval_cls)\n",
      "File \u001b[0;32m~/depmbt/vitmbt.py:328\u001b[0m, in \u001b[0;36mtrain_audio\u001b[0;34m(net, trainldr, optimizer, loss_fn, cls_metrics)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(trainldr):\n\u001b[1;32m    327\u001b[0m     audio, _, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m--> 328\u001b[0m     audio \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m    329\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    330\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_metrics = train(vmbt, train_dl, optimizer, loss_fn=loss_func, cls_metrics=train_cls)\n",
    "    train_loss, train_f1, train_r, train_p, train_acc = train_metrics\n",
    "    val_metrics = val(vmbt, val_dl, loss_fn=loss_func, cls_metrics=val_cls)\n",
    "    val_loss, val_f1, val_r, val_p, val_acc = val_metrics\n",
    "\n",
    "    print(\n",
    "        (f\"Epoch {epoch + 1}: train_loss {train_loss:.5f}, val_loss {val_loss:.5f}\\n\"\n",
    "            f\"                   train_precision {train_p}, val_precision {val_p}\\n\"\n",
    "            f\"                   train_recall {train_r}, val_recall {val_r}\\n\"\n",
    "            f\"                   train_f1 {train_f1}, val_f1 {val_f1}\"\n",
    "            )\n",
    "        )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depmbt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
