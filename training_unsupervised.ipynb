{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCELoss\n",
    "import torch.nn as nn\n",
    "from pprint import pformat\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import vitmbt\n",
    "import mbt\n",
    "import ablation\n",
    "import helpers\n",
    "reload(mbt)\n",
    "reload(ablation)\n",
    "reload(helpers)\n",
    "reload(vitmbt)\n",
    "from helpers import ClassifierMetrics\n",
    "from vitmbt import ViTMBT, train, val\n",
    "from data import load_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from constants import *\n",
    "from loss import multicrop_loss\n",
    "\n",
    "import torch.optim.lr_scheduler as lrsch\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "RESULTS = \"results/best.txt\"\n",
    "PRETRAINED_CHKPT = \"./pretrained_models/L_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.1-sd_0.1--imagenet2012-steps_20k-lr_0.01-res_224.npz\"\n",
    "WARMUP_EPOCHS = 5\n",
    "EPOCHS = WARMUP_EPOCHS + 30\n",
    "lr = 0.00005\n",
    "betas = (0.9, 0.999)\n",
    "momentum = 0.9\n",
    "BATCH_SZ = 2\n",
    "LABELS = 8\n",
    "SPLIT = [0.95, 0.05, 0.0]\n",
    "SPLIT = [1, 0.0, 0.0]\n",
    "MILESTONES = [WARMUP_EPOCHS]\n",
    "T_0 = 6\n",
    "PT_ATTN_DROPOUT = 0.15\n",
    "ATTN_DROPOUT = 0.4\n",
    "LINEAR_DROPOUT = 0.1\n",
    "BOTTLE_LAYER = 10\n",
    "FREEZE_FIRST = 8\n",
    "TOTAL_LAYERS = 14\n",
    "APPLY_AUG = True\n",
    "\n",
    "train_dl, val_dl, test_dl  = load_data(f\"{DATA_DIR}/Labels/all_pruned.csv\", \n",
    "                                       batch_sz=BATCH_SZ,\n",
    "                                       train_val_test_split=SPLIT, nlines=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio layers...\n",
      "torch.Size([1, 1, 1024]) torch.Size([1, 184, 1024])\n",
      "Loaded successfully in 3.8s\n",
      "Loading video layers...\n",
      "Loaded successfully in 3.8s\n",
      "Reset trainable parameters of layer = 8.norm1\n",
      "Reset trainable parameters of layer = 8.attn.qkv\n",
      "Reset trainable parameters of layer = 8.attn.proj\n",
      "Reset trainable parameters of layer = 8.norm2\n",
      "Reset trainable parameters of layer = 8.mlp.fc1\n",
      "Reset trainable parameters of layer = 8.mlp.fc2\n",
      "Reset trainable parameters of layer = 9.norm1\n",
      "Reset trainable parameters of layer = 9.attn.qkv\n",
      "Reset trainable parameters of layer = 9.attn.proj\n",
      "Reset trainable parameters of layer = 9.norm2\n",
      "Reset trainable parameters of layer = 9.mlp.fc1\n",
      "Reset trainable parameters of layer = 9.mlp.fc2\n",
      "Reset trainable parameters of layer = 8.norm1\n",
      "Reset trainable parameters of layer = 8.attn.qkv\n",
      "Reset trainable parameters of layer = 8.attn.proj\n",
      "Reset trainable parameters of layer = 8.norm2\n",
      "Reset trainable parameters of layer = 8.mlp.fc1\n",
      "Reset trainable parameters of layer = 8.mlp.fc2\n",
      "Reset trainable parameters of layer = 9.norm1\n",
      "Reset trainable parameters of layer = 9.attn.qkv\n",
      "Reset trainable parameters of layer = 9.attn.proj\n",
      "Reset trainable parameters of layer = 9.norm2\n",
      "Reset trainable parameters of layer = 9.mlp.fc1\n",
      "Reset trainable parameters of layer = 9.mlp.fc2\n",
      "Loading audio layers...\n",
      "torch.Size([1, 1, 1024]) torch.Size([1, 184, 1024])\n",
      "Loaded successfully in 3.7s\n",
      "Loading video layers...\n",
      "Loaded successfully in 3.8s\n",
      "Reset trainable parameters of layer = 8.norm1\n",
      "Reset trainable parameters of layer = 8.attn.qkv\n",
      "Reset trainable parameters of layer = 8.attn.proj\n",
      "Reset trainable parameters of layer = 8.norm2\n",
      "Reset trainable parameters of layer = 8.mlp.fc1\n",
      "Reset trainable parameters of layer = 8.mlp.fc2\n",
      "Reset trainable parameters of layer = 9.norm1\n",
      "Reset trainable parameters of layer = 9.attn.qkv\n",
      "Reset trainable parameters of layer = 9.attn.proj\n",
      "Reset trainable parameters of layer = 9.norm2\n",
      "Reset trainable parameters of layer = 9.mlp.fc1\n",
      "Reset trainable parameters of layer = 9.mlp.fc2\n",
      "Reset trainable parameters of layer = 8.norm1\n",
      "Reset trainable parameters of layer = 8.attn.qkv\n",
      "Reset trainable parameters of layer = 8.attn.proj\n",
      "Reset trainable parameters of layer = 8.norm2\n",
      "Reset trainable parameters of layer = 8.mlp.fc1\n",
      "Reset trainable parameters of layer = 8.mlp.fc2\n",
      "Reset trainable parameters of layer = 9.norm1\n",
      "Reset trainable parameters of layer = 9.attn.qkv\n",
      "Reset trainable parameters of layer = 9.attn.proj\n",
      "Reset trainable parameters of layer = 9.norm2\n",
      "Reset trainable parameters of layer = 9.mlp.fc1\n",
      "Reset trainable parameters of layer = 9.mlp.fc2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mbt_teacher = ViTMBT(1024, num_class=LABELS, no_class=False, bottle_layer=BOTTLE_LAYER, freeze_first=FREEZE_FIRST, num_layers=TOTAL_LAYERS, apply_augmentation=APPLY_AUG, attn_drop=ATTN_DROPOUT, linear_drop=LINEAR_DROPOUT)\n",
    "mbt_teacher = nn.DataParallel(mbt_teacher).cuda()\n",
    "\n",
    "mbt_student = ViTMBT(1024, num_class=LABELS, no_class=False, bottle_layer=BOTTLE_LAYER, freeze_first=FREEZE_FIRST, num_layers=TOTAL_LAYERS, apply_augmentation=APPLY_AUG, attn_drop=ATTN_DROPOUT, linear_drop=LINEAR_DROPOUT)\n",
    "mbt_student = nn.DataParallel(mbt_student).cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# only the student's weights are updated by the optimiser\n",
    "optimizer = torch.optim.AdamW(mbt_student.parameters(), betas=(0.9, 0.999), lr=lr, weight_decay=0.4)\n",
    "\n",
    "scheduler = lrsch.SequentialLR(\n",
    "    optimizer=optimizer,\n",
    "    schedulers=[\n",
    "    lrsch.ConstantLR(optimizer=optimizer, factor=1, total_iters=WARMUP_EPOCHS),\n",
    "    lrsch.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=T_0)\n",
    "], milestones=MILESTONES)\n",
    "\n",
    "\n",
    "\n",
    "train_cls = ClassifierMetrics(task='multilabel', n_labels=LABELS, device=DEVICE)\n",
    "val_cls = ClassifierMetrics(task='multilabel', n_labels=LABELS, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1ba466d55b4f378fd7c5892405dec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     train_loss, train_metrics \u001b[39m=\u001b[39m train(mbt_teacher, mbt_student, train_dl, optimizer, CENTRE_CONSTANT, loss_fn\u001b[39m=\u001b[39mmulticrop_loss)\n\u001b[1;32m      3\u001b[0m     val_loss, val_metrics \u001b[39m=\u001b[39m val(mbt_teacher, mbt_student, val_dl, CENTRE_CONSTANT, loss_fn\u001b[39m=\u001b[39mmulticrop_loss)\n\u001b[1;32m      4\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(mbt_teacher, mbt_student, train_dl, optimizer, CENTRE_CONSTANT, loss_fn=multicrop_loss)\n",
    "    val_loss = val(mbt_teacher, mbt_student, val_dl, CENTRE_CONSTANT, loss_fn=multicrop_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        (f\"Epoch {epoch + 1}: train_loss {train_loss:.5f}, val_loss {val_loss:.5f}\\n\")\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depmbt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
